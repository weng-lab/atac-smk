{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b40826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import polars as pl\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from multiprocessing import get_context\n",
    "# from pathos.multiprocessing import ProcessPool as Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "# os.environ[\"POLARS_MAX_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d12020",
   "metadata": {},
   "source": [
    "Message from Huong:\n",
    "\n",
    "> Here's the main script for computing signal (can be ATAC, DNase,...) zscores that Jill made for ENCODE4 cCRE pipeline https://github.com/weng-lab/ENCODE-cCREs/blob/master/Version-4/cCRE-Pipeline/4_Calculate-Signal-Zscores.sh\n",
    ">\n",
    "> Other scripts you need are Retrieve-Signal.sh and log-zscore-normalization.py in ~/GitHub/ENCODE-cCREs/Version-4/cCRE-Pipeline/Toolkit\n",
    ">\n",
    "> Just adapt these scripts to your working directories. Anchors files are at /data/projects/encode/Registry/V4/{GRCh38,mm10}/{GRCh38,mm10}-Anchors.bed cCREs files are at /data/projects/encode/Registry/V4/{GRCh38,mm10}/{GRCh38,mm10}-cCREs.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36eea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRCh38\n",
      "ATAC\n",
      "./run_ccre_pipeline\n",
      "./run_ccre_pipeline/ATAC-List.txt\n",
      "./run_ccre_pipeline/signal-output\n",
      "./run_ccre_pipeline/bigwigaverageoverbed-output\n",
      "/zata/data/zlab/zusers/moorej3/moorej.ghpcc.project/ENCODE/Encyclopedia/V7/Registry/V7-hg38/hg38-Anchors.bed\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "GENOME = \"GRCh38\"\n",
    "MODE = \"ATAC\"\n",
    "OUTDIR = \"./run_ccre_pipeline\"\n",
    "FILES_CATALOG = os.path.join(OUTDIR, f\"{MODE}-List.txt\")\n",
    "SIGNAL_OUT = os.path.join(OUTDIR, \"signal-output\")\n",
    "BIGWIGAVERAGEOVERBED = os.path.join(OUTDIR, \"bigwigaverageoverbed-output\")\n",
    "ANCHORS = \"/zata/data/zlab/zusers/moorej3/moorej.ghpcc.project/ENCODE/Encyclopedia/V7/Registry/V7-hg38/hg38-Anchors.bed\"\n",
    "WIDTH = 0 if MODE in [\"DNase\", \"CTCF\", \"POL2\", \"ATAC\"] else 500\n",
    "LITTLE = os.path.join(OUTDIR, 'little.txt')\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "os.makedirs(SIGNAL_OUT, exist_ok=True)\n",
    "os.makedirs(BIGWIGAVERAGEOVERBED, exist_ok=True)\n",
    "\n",
    "print(GENOME, MODE, OUTDIR, FILES_CATALOG, SIGNAL_OUT, BIGWIGAVERAGEOVERBED, ANCHORS, WIDTH, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147a766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = pl.read_csv(ANCHORS, separator='\\t', has_header=False, new_columns=['chrom', 'start', 'end', 'name'])\n",
    "\n",
    "little = peaks.with_columns(\n",
    "    pl.col('start') - WIDTH,\n",
    "    pl.col('end') + WIDTH,\n",
    ").with_columns(\n",
    "    pl.col('start').clip(lower_bound=0)\n",
    ").unique().sort('chrom', 'start')\n",
    "\n",
    "little.write_csv(LITTLE, separator='\\t', include_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f38782",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigwig_files = glob.glob(\"../results/macs3_signal/*.bigWig\")\n",
    "pattern = r\"../results/macs3_signal/(.*)-GRCH38.bigWig\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in bigwig_files:\n",
    "    records.append(dict(sample=re.search(pattern, file).group(1), bigwig=file))\n",
    "    \n",
    "input_df = pl.from_records(records).sort('sample')\n",
    "args = list(zip(input_df['sample'].to_list(), input_df['bigwig'].to_list(), [LITTLE] * input_df.shape[0]))\n",
    "input_df.write_csv(FILES_CATALOG, separator=\"\\t\", include_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdece358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_signal(args):\n",
    "    sample, bigwig_file, little_bed_file = args\n",
    "    bwavgoverbed_output = subprocess.run([\"bigwigaverageoverbed\", \"-t\", \"1\", bigwig_file, little_bed_file, \"/dev/stdout\"], check=True, capture_output=True, text=True)\n",
    "    bed_file = StringIO(bwavgoverbed_output.stdout)\n",
    "    bed_df = pl.read_csv(bed_file, separator=\"\\t\", has_header=False, new_columns=[\"name\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\"])\n",
    "    bed_df_processed = bed_df.with_columns(\n",
    "        pl.when((pl.col(\"covered\") == 0) | (pl.col(\"mean0\") == 0))\n",
    "        .then(pl.lit(0))\n",
    "        .otherwise(pl.col(\"mean0\").log10())\n",
    "        .alias(\"log10(mean0)\")\n",
    "    ).with_columns(\n",
    "        pl.when((pl.col(\"covered\") == 0) | (pl.col(\"mean0\") == 0))\n",
    "        .then(pl.lit(-10))\n",
    "        .otherwise((pl.col(\"log10(mean0)\") - pl.col(\"log10(mean0)\").mean()) / pl.col(\"log10(mean0)\").std())\n",
    "        .alias(\"zscore\")\n",
    "    ).sort(\n",
    "        \"zscore\",\n",
    "        descending=True\n",
    "    ).with_columns(\n",
    "        pl.col('zscore').rank(method=\"min\", descending=True).alias(\"rank\")\n",
    "    ).sort('name')\n",
    "    outfile = os.path.join(SIGNAL_OUT, sample + \".txt\")\n",
    "    bed_df_processed.write_csv(outfile, include_header=False, separator=\"\\t\")\n",
    "    return {\"sample\": sample, \"no_ccres_with_zscore_gt_1.64\": bed_df_processed.filter(pl.col(\"zscore\") > 1.64).count()['zscore'].item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73901d28",
   "metadata": {},
   "source": [
    "Output schema?\n",
    "\n",
    "- `name`: name field from bed, which should be unique\n",
    "- `size`: size of bed (sum of exon sizes)\n",
    "- `covered`: # bases within exons covered by bigWig\n",
    "- `sum`: sum of values over all bases covered\n",
    "- `mean0`: average over bases with non-covered bases counting as zeroes\n",
    "- `mean`: average over just covered base\n",
    "- `log(mean0)`: log of mean0\n",
    "- `zscore`: (log(mean0) - log(mean0).mean()) / log(mean0).std()\n",
    "- `rank`: rank of zscore\n",
    "\n",
    "```python\n",
    "schema = {\n",
    "    'name': pl.Utf8,           # Unique identifier from BED file\n",
    "    'size': pl.UInt32,         # Size of BED region (sum of exon sizes)\n",
    "    'covered': pl.UInt32,      # Number of bases covered by bigWig\n",
    "    'sum': pl.Float64,         # Sum of values over all covered bases\n",
    "    'mean0': pl.Float64,       # Average (non-covered bases = 0)\n",
    "    'mean': pl.Float64,        # Average over only covered bases\n",
    "    'log10(mean0)': pl.Float64,# log10(mean0)\n",
    "    'zscore': pl.Float64,      # (log_mean0 - mean) / std\n",
    "    'rank': pl.UInt32          # Rank by zscore (descending)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3c7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ThreadPoolExecutor(max_workers=164) as executor:\n",
    "# # with ProcessPoolExecutor(max_workers=96) as executor:\n",
    "# # with Pool(96) as executor:\n",
    "#     records = list(tqdm(executor.map(retrieve_signal, args), total=len(args), desc=\"Retrieving Signal\"))\n",
    "\n",
    "# # records = tqdm([retrieve_signal(arg) for arg in args], total=len(args), desc=\"Retrieving Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f2c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_bigwigaverageoverbed(args):\n",
    "#     sample, bigwig_file, little_bed_file = args\n",
    "    \n",
    "#     result = subprocess.run(\n",
    "#         [\"bigwigaverageoverbed\", \"-t\", \"2\", bigwig_file, little_bed_file, \"/dev/stdout\"],\n",
    "#         capture_output=True,\n",
    "#         check=True\n",
    "#     )\n",
    "#     bed_df = (\n",
    "#         pl.read_csv(\n",
    "#             result.stdout,\n",
    "#             separator=\"\\t\",\n",
    "#             has_header=False,\n",
    "#             new_columns=[\"name\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\"]\n",
    "#         )\n",
    "#         .with_columns(pl.lit(sample).alias(\"sample\"))\n",
    "#     )\n",
    "\n",
    "#     new_path = os.path.join(BIGWIGAVERAGEOVERBED, sample + \".txt\")\n",
    "#     bed_df.write_csv(new_path, include_header=False, separator=\"\\t\")\n",
    "\n",
    "#     return {\"sample\": sample, \"path\": new_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c647c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bigwigaverageoverbed(args):\n",
    "    sample, bigwig_file, little_bed_file = args\n",
    "    output_file = os.path.join(BIGWIGAVERAGEOVERBED, f\"sample={sample}\", f\"{sample}.csv\")\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    cmd = f\"\"\"\n",
    "    echo \"name,size,covered,sum,mean0,mean\" > {output_file} && \\\n",
    "    bigwigaverageoverbed -t 2 {bigwig_file} {little_bed_file} /dev/stdout | tr '\\\\t' ',' >> {output_file}\n",
    "    \"\"\"\n",
    "    subprocess.run(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        check=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f070965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running bigwigaverageoverbed: 100%|██████████| 154/154 [00:33<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=164) as executor:\n",
    "# with ProcessPoolExecutor(max_workers=96) as executor:\n",
    "# with Pool(96) as executor:\n",
    "    # records = list(tqdm(executor.map(run_bigwigaverageoverbed, args), total=len(args), desc=\"Running bigwigaverageoverbed\"))\n",
    "    list(tqdm(executor.map(run_bigwigaverageoverbed, args), total=len(args), desc=\"Running bigwigaverageoverbed\"))\n",
    "\n",
    "# records = tqdm([retrieve_signal(arg) for arg in args], total=len(args), desc=\"Retrieving Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dbd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (454_335_112, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>size</th><th>covered</th><th>sum</th><th>mean0</th><th>mean</th><th>sample</th><th>log10(mean0)</th><th>zscore</th><th>rank</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;EH38D0001261&quot;</td><td>291</td><td>291</td><td>1527.0</td><td>5.247</td><td>5.247</td><td>&quot;EA100001&quot;</td><td>0.719911</td><td>1.00846</td><td>393360</td></tr><tr><td>&quot;EH38D0001472&quot;</td><td>314</td><td>314</td><td>1492.0</td><td>4.752</td><td>4.752</td><td>&quot;EA100001&quot;</td><td>0.676876</td><td>0.902282</td><td>496040</td></tr><tr><td>&quot;EH38D0002482&quot;</td><td>341</td><td>341</td><td>3707.0</td><td>10.871</td><td>10.871</td><td>&quot;EA100001&quot;</td><td>1.036269</td><td>1.789002</td><td>39076</td></tr><tr><td>&quot;EH38D0004420&quot;</td><td>223</td><td>223</td><td>918.0</td><td>4.117</td><td>4.117</td><td>&quot;EA100001&quot;</td><td>0.614581</td><td>0.748582</td><td>664624</td></tr><tr><td>&quot;EH38D0004750&quot;</td><td>201</td><td>201</td><td>508.0</td><td>2.527</td><td>2.527</td><td>&quot;EA100001&quot;</td><td>0.402605</td><td>0.225581</td><td>1328020</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;EH38F0086744&quot;</td><td>163</td><td>163</td><td>823.0</td><td>5.049</td><td>5.049</td><td>&quot;EA100154&quot;</td><td>0.703205</td><td>0.254985</td><td>1297489</td></tr><tr><td>&quot;EH38F0086745&quot;</td><td>342</td><td>342</td><td>1241.0</td><td>3.629</td><td>3.629</td><td>&quot;EA100154&quot;</td><td>0.559787</td><td>-0.184023</td><td>1873464</td></tr><tr><td>&quot;EH38F0086746&quot;</td><td>320</td><td>320</td><td>570.0</td><td>1.781</td><td>1.781</td><td>&quot;EA100154&quot;</td><td>0.250664</td><td>-1.130258</td><td>2605437</td></tr><tr><td>&quot;EH38F0086747&quot;</td><td>350</td><td>350</td><td>2607.0</td><td>7.449</td><td>7.449</td><td>&quot;EA100154&quot;</td><td>0.872098</td><td>0.77197</td><td>618278</td></tr><tr><td>&quot;EH38F0086748&quot;</td><td>350</td><td>350</td><td>1051.0</td><td>3.003</td><td>3.003</td><td>&quot;EA100154&quot;</td><td>0.477555</td><td>-0.435737</td><td>2141747</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (454_335_112, 10)\n",
       "┌──────────────┬──────┬─────────┬────────┬───┬──────────┬──────────────┬───────────┬─────────┐\n",
       "│ name         ┆ size ┆ covered ┆ sum    ┆ … ┆ sample   ┆ log10(mean0) ┆ zscore    ┆ rank    │\n",
       "│ ---          ┆ ---  ┆ ---     ┆ ---    ┆   ┆ ---      ┆ ---          ┆ ---       ┆ ---     │\n",
       "│ str          ┆ i64  ┆ i64     ┆ f64    ┆   ┆ str      ┆ f64          ┆ f64       ┆ u32     │\n",
       "╞══════════════╪══════╪═════════╪════════╪═══╪══════════╪══════════════╪═══════════╪═════════╡\n",
       "│ EH38D0001261 ┆ 291  ┆ 291     ┆ 1527.0 ┆ … ┆ EA100001 ┆ 0.719911     ┆ 1.00846   ┆ 393360  │\n",
       "│ EH38D0001472 ┆ 314  ┆ 314     ┆ 1492.0 ┆ … ┆ EA100001 ┆ 0.676876     ┆ 0.902282  ┆ 496040  │\n",
       "│ EH38D0002482 ┆ 341  ┆ 341     ┆ 3707.0 ┆ … ┆ EA100001 ┆ 1.036269     ┆ 1.789002  ┆ 39076   │\n",
       "│ EH38D0004420 ┆ 223  ┆ 223     ┆ 918.0  ┆ … ┆ EA100001 ┆ 0.614581     ┆ 0.748582  ┆ 664624  │\n",
       "│ EH38D0004750 ┆ 201  ┆ 201     ┆ 508.0  ┆ … ┆ EA100001 ┆ 0.402605     ┆ 0.225581  ┆ 1328020 │\n",
       "│ …            ┆ …    ┆ …       ┆ …      ┆ … ┆ …        ┆ …            ┆ …         ┆ …       │\n",
       "│ EH38F0086744 ┆ 163  ┆ 163     ┆ 823.0  ┆ … ┆ EA100154 ┆ 0.703205     ┆ 0.254985  ┆ 1297489 │\n",
       "│ EH38F0086745 ┆ 342  ┆ 342     ┆ 1241.0 ┆ … ┆ EA100154 ┆ 0.559787     ┆ -0.184023 ┆ 1873464 │\n",
       "│ EH38F0086746 ┆ 320  ┆ 320     ┆ 570.0  ┆ … ┆ EA100154 ┆ 0.250664     ┆ -1.130258 ┆ 2605437 │\n",
       "│ EH38F0086747 ┆ 350  ┆ 350     ┆ 2607.0 ┆ … ┆ EA100154 ┆ 0.872098     ┆ 0.77197   ┆ 618278  │\n",
       "│ EH38F0086748 ┆ 350  ┆ 350     ┆ 1051.0 ┆ … ┆ EA100154 ┆ 0.477555     ┆ -0.435737 ┆ 2141747 │\n",
       "└──────────────┴──────┴─────────┴────────┴───┴──────────┴──────────────┴───────────┴─────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multi_bed_df = pl.read_csv(os.path.join(BIGWIGAVERAGEOVERBED, \"*.txt\"), has_header=False, separator=\"\\t\", new_columns=[\"name\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\", \"sample\"])\n",
    "\n",
    "schema = pa.schema([\n",
    "    (\"name\", pa.string()),\n",
    "    (\"size\", pa.int64()),\n",
    "    (\"covered\", pa.int64()),\n",
    "    (\"sum\", pa.float64()),\n",
    "    (\"mean0\", pa.float64()),\n",
    "    (\"mean\", pa.float64()),\n",
    "    (\"sample\", pa.string())\n",
    "])\n",
    "\n",
    "dataset = ds.dataset(BIGWIGAVERAGEOVERBED, format='csv', partitioning='hive', schema=schema)\n",
    "multi_bed_df = pl.scan_pyarrow_dataset(dataset)\n",
    "# multi_bed_df = pl.scan_csv(BIGWIGAVERAGEOVERBED, has_header=False, separator=\"\\t\", new_columns=[\"name\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\", \"sample\"])\n",
    "\n",
    "multi_bed_df_processed = multi_bed_df.with_columns(\n",
    "    pl.when((pl.col(\"covered\") == 0) | (pl.col(\"mean0\") == 0))\n",
    "    .then(pl.lit(0))\n",
    "    .otherwise(pl.col(\"mean0\").log10())\n",
    "    .over('sample').alias(\"log10(mean0)\")\n",
    ").with_columns(\n",
    "    pl.when((pl.col(\"covered\") == 0) | (pl.col(\"mean0\") == 0))\n",
    "    .then(pl.lit(-10))\n",
    "    .otherwise((pl.col(\"log10(mean0)\") - pl.col(\"log10(mean0)\").mean()) / pl.col(\"log10(mean0)\").std())\n",
    "    .over('sample').alias(\"zscore\")\n",
    ").sort(\n",
    "    \"zscore\",\n",
    "    descending=True\n",
    ").with_columns(\n",
    "    pl.col('zscore').rank(method=\"min\", descending=True).over('sample').alias(\"rank\")\n",
    ").sort('sample', 'name').collect()\n",
    "\n",
    "display(multi_bed_df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records_df = pl.from_records(records)\n",
    "# records_df.write_csv(os.path.join(OUTDIR, \"ccres_qc.tsv\"), separator=\"\\t\")\n",
    "# print(*records_df.sort('sample')['no_ccres_with_zscore_gt_1.64'].to_list(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_bed_zscore_gt_threshold = multi_bed_df_processed.filter(pl.col(\"zscore\") > 1.64).group_by(\"sample\").len('zscore').sort('sample')\n",
    "display(multi_bed_zscore_gt_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'name': pl.Utf8,           # Unique identifier from BED file\n",
    "    'size': pl.UInt32,         # Size of BED region (sum of exon sizes)\n",
    "    'covered': pl.UInt32,      # Number of bases covered by bigWig\n",
    "    'sum': pl.Float64,         # Sum of values over all covered bases\n",
    "    'mean0': pl.Float64,       # Average (non-covered bases = 0)\n",
    "    'mean': pl.Float64,        # Average over only covered bases\n",
    "    'log10(mean0)': pl.Float64,   # log10(mean0)\n",
    "    'zscore': pl.Float64,      # (log10(mean0) - log10(mean)) / std(log10(mean0))\n",
    "    'rank': pl.UInt32          # Rank by zscore (descending)\n",
    "}\n",
    "\n",
    "all_signals = pl.scan_csv(os.path.join(SIGNAL_OUT, \"*.txt\"), separator=\"\\t\", has_header=False, schema=schema)\n",
    "maxz_df = all_signals.select('name', 'zscore').group_by('name').agg(pl.col('zscore').max().alias('maxz')).collect()\n",
    "display(maxz_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54506b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxz_df.sort('name').write_csv(os.path.join(OUTDIR, f'hg38-{MODE}-maxz.txt'), separator='\\t', include_header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atac-smk (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
